{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-11T13:44:57.506769Z",
     "start_time": "2024-02-11T13:44:55.449381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in ./venv/lib/python3.9/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in ./venv/lib/python3.9/site-packages (from sentence-transformers) (4.36.1)\r\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (from sentence-transformers) (4.66.1)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in ./venv/lib/python3.9/site-packages (from sentence-transformers) (2.1.2)\r\n",
      "Requirement already satisfied: torchvision in ./venv/lib/python3.9/site-packages (from sentence-transformers) (0.16.2)\r\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (from sentence-transformers) (1.26.3)\r\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.9/site-packages (from sentence-transformers) (1.3.2)\r\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.9/site-packages (from sentence-transformers) (1.11.4)\r\n",
      "Requirement already satisfied: nltk in ./venv/lib/python3.9/site-packages (from sentence-transformers) (3.8.1)\r\n",
      "Requirement already satisfied: sentencepiece in ./venv/lib/python3.9/site-packages (from sentence-transformers) (0.1.99)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in ./venv/lib/python3.9/site-packages (from sentence-transformers) (0.19.4)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.12.2)\r\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.9.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\r\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\r\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.10.3)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\r\n",
      "Requirement already satisfied: click in ./venv/lib/python3.9/site-packages (from nltk->sentence-transformers) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.9/site-packages (from nltk->sentence-transformers) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./venv/lib/python3.9/site-packages (from torchvision->sentence-transformers) (10.1.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in ./venv/lib/python3.9/site-packages (0.19.4)\r\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from huggingface_hub) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.9/site-packages (from huggingface_hub) (2023.12.2)\r\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (from huggingface_hub) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./venv/lib/python3.9/site-packages (from huggingface_hub) (4.66.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.9/site-packages (from huggingface_hub) (6.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.9/site-packages (from huggingface_hub) (4.9.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.9/site-packages (from huggingface_hub) (23.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests->huggingface_hub) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests->huggingface_hub) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests->huggingface_hub) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests->huggingface_hub) (2023.11.17)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T13:45:04.123304Z",
     "start_time": "2024-02-11T13:45:01.930403Z"
    }
   },
   "id": "3f4bb6448b121204"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./venv/lib/python3.9/site-packages (0.0.350)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.9/site-packages (from langchain) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.9/site-packages (from langchain) (2.0.23)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.9/site-packages (from langchain) (3.9.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./venv/lib/python3.9/site-packages (from langchain) (4.0.3)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./venv/lib/python3.9/site-packages (from langchain) (0.6.3)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.9/site-packages (from langchain) (1.33)\r\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.2 in ./venv/lib/python3.9/site-packages (from langchain) (0.0.3)\r\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1 in ./venv/lib/python3.9/site-packages (from langchain) (0.1.1)\r\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in ./venv/lib/python3.9/site-packages (from langchain) (0.0.71)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in ./venv/lib/python3.9/site-packages (from langchain) (1.26.3)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./venv/lib/python3.9/site-packages (from langchain) (2.5.2)\r\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.9/site-packages (from langchain) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./venv/lib/python3.9/site-packages (from langchain) (8.2.3)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\r\n",
      "Requirement already satisfied: anyio<5,>=3 in ./venv/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1->langchain) (3.7.1)\r\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in ./venv/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./venv/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in ./venv/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (2.14.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./venv/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2023.11.17)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.2)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in ./venv/lib/python3.9/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.3.0)\r\n",
      "Requirement already satisfied: exceptiongroup in ./venv/lib/python3.9/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.2.0)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T13:45:13.759300Z",
     "start_time": "2024-02-11T13:45:11.617943Z"
    }
   },
   "id": "4dac3b0b373f47e7"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[31mERROR: No matching distribution found for faiss-gpu\u001B[0m\u001B[31m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T13:45:19.427435Z",
     "start_time": "2024-02-11T13:45:18.409602Z"
    }
   },
   "id": "ba9b801b55100349"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pip 24.0 from /Users/Siar/Desktop/AWT-repos/generative-agents/venv/lib/python3.9/site-packages/pip (python 3.9)\r\n",
      "Collecting llama-cpp-python==0.1.78\r\n",
      "  Downloading llama_cpp_python-0.1.78.tar.gz (1.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m17.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25h  Running command pip subprocess to install build dependencies\r\n",
      "  Collecting setuptools>=42\r\n",
      "    Using cached setuptools-69.0.3-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "  Collecting scikit-build>=0.13\r\n",
      "    Using cached scikit_build-0.17.6-py3-none-any.whl.metadata (14 kB)\r\n",
      "  Collecting cmake>=3.18\r\n",
      "    Downloading cmake-3.28.3-py2.py3-none-macosx_10_10_universal2.macosx_10_10_x86_64.macosx_11_0_arm64.macosx_11_0_universal2.whl.metadata (6.3 kB)\r\n",
      "  Collecting ninja\r\n",
      "    Using cached ninja-1.11.1.1-py2.py3-none-macosx_10_9_universal2.macosx_10_9_x86_64.macosx_11_0_arm64.macosx_11_0_universal2.whl.metadata (5.3 kB)\r\n",
      "  Collecting distro (from scikit-build>=0.13)\r\n",
      "    Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "  Collecting packaging (from scikit-build>=0.13)\r\n",
      "    Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "  Collecting tomli (from scikit-build>=0.13)\r\n",
      "    Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\r\n",
      "  Collecting wheel>=0.32.0 (from scikit-build>=0.13)\r\n",
      "    Using cached wheel-0.42.0-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "  Using cached setuptools-69.0.3-py3-none-any.whl (819 kB)\r\n",
      "  Using cached scikit_build-0.17.6-py3-none-any.whl (84 kB)\r\n",
      "  Downloading cmake-3.28.3-py2.py3-none-macosx_10_10_universal2.macosx_10_10_x86_64.macosx_11_0_arm64.macosx_11_0_universal2.whl (48.5 MB)\r\n",
      "  \u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/48.5 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\n",
      "  \u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.1/48.5 MB\u001B[0m \u001B[31m3.7 MB/s\u001B[0m eta \u001B[36m0:00:14\u001B[0m\r\n",
      "  \u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.6/48.5 MB\u001B[0m \u001B[31m8.2 MB/s\u001B[0m eta \u001B[36m0:00:06\u001B[0m\r\n",
      "  \u001B[2K   \u001B[91m━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/48.5 MB\u001B[0m \u001B[31m18.9 MB/s\u001B[0m eta \u001B[36m0:00:03\u001B[0m\r\n",
      "  \u001B[2K   \u001B[91m━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.8/48.5 MB\u001B[0m \u001B[31m40.5 MB/s\u001B[0m eta \u001B[36m0:00:02\u001B[0m\r\n",
      "  \u001B[2K   \u001B[91m━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m8.4/48.5 MB\u001B[0m \u001B[31m50.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "  \u001B[2K   \u001B[91m━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.0/48.5 MB\u001B[0m \u001B[31m101.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "  \u001B[2K   \u001B[91m━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m16.7/48.5 MB\u001B[0m \u001B[31m101.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "  \u001B[2K   \u001B[91m━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m16.9/48.5 MB\u001B[0m \u001B[31m75.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "  \u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m23.1/48.5 MB\u001B[0m \u001B[31m93.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "  \u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m25.2/48.5 MB\u001B[0m \u001B[31m94.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "  \u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━\u001B[0m \u001B[32m30.0/48.5 MB\u001B[0m \u001B[31m99.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "  \u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━\u001B[0m \u001B[32m33.5/48.5 MB\u001B[0m \u001B[31m94.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "  \u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━\u001B[0m \u001B[32m35.9/48.5 MB\u001B[0m \u001B[31m105.8 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "  \u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━\u001B[0m \u001B[32m40.7/48.5 MB\u001B[0m \u001B[31m98.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "  \u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━\u001B[0m \u001B[32m42.6/48.5 MB\u001B[0m \u001B[31m83.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "  \u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m \u001B[32m47.4/48.5 MB\u001B[0m \u001B[31m100.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "  \u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m48.5/48.5 MB\u001B[0m \u001B[31m101.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "  \u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m48.5/48.5 MB\u001B[0m \u001B[31m101.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\n",
      "  \u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m48.5/48.5 MB\u001B[0m \u001B[31m54.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "  \u001B[?25hUsing cached ninja-1.11.1.1-py2.py3-none-macosx_10_9_universal2.macosx_10_9_x86_64.macosx_11_0_arm64.macosx_11_0_universal2.whl (270 kB)\r\n",
      "  Using cached wheel-0.42.0-py3-none-any.whl (65 kB)\r\n",
      "  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\r\n",
      "  Using cached packaging-23.2-py3-none-any.whl (53 kB)\r\n",
      "  Installing collected packages: ninja, cmake, wheel, tomli, setuptools, packaging, distro, scikit-build\r\n",
      "  Successfully installed cmake-3.28.3 distro-1.9.0 ninja-1.11.1.1 packaging-23.2 scikit-build-0.17.6 setuptools-69.0.3 tomli-2.0.1 wheel-0.42.0\r\n",
      "  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\r\n",
      "  Running command Getting requirements to build wheel\r\n",
      "  running egg_info\r\n",
      "  writing llama_cpp_python.egg-info/PKG-INFO\r\n",
      "  writing dependency_links to llama_cpp_python.egg-info/dependency_links.txt\r\n",
      "  writing requirements to llama_cpp_python.egg-info/requires.txt\r\n",
      "  writing top-level names to llama_cpp_python.egg-info/top_level.txt\r\n",
      "  reading manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\r\n",
      "  adding license file 'LICENSE.md'\r\n",
      "  writing manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\r\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\r\n",
      "  Running command Preparing metadata (pyproject.toml)\r\n",
      "  running dist_info\r\n",
      "  creating /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-modern-metadata-q3ffv0vg/llama_cpp_python.egg-info\r\n",
      "  writing /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-modern-metadata-q3ffv0vg/llama_cpp_python.egg-info/PKG-INFO\r\n",
      "  writing dependency_links to /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-modern-metadata-q3ffv0vg/llama_cpp_python.egg-info/dependency_links.txt\r\n",
      "  writing requirements to /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-modern-metadata-q3ffv0vg/llama_cpp_python.egg-info/requires.txt\r\n",
      "  writing top-level names to /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-modern-metadata-q3ffv0vg/llama_cpp_python.egg-info/top_level.txt\r\n",
      "  writing manifest file '/private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-modern-metadata-q3ffv0vg/llama_cpp_python.egg-info/SOURCES.txt'\r\n",
      "  reading manifest file '/private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-modern-metadata-q3ffv0vg/llama_cpp_python.egg-info/SOURCES.txt'\r\n",
      "  adding license file 'LICENSE.md'\r\n",
      "  writing manifest file '/private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-modern-metadata-q3ffv0vg/llama_cpp_python.egg-info/SOURCES.txt'\r\n",
      "  creating '/private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-modern-metadata-q3ffv0vg/llama_cpp_python-0.1.78.dist-info'\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\r\n",
      "Collecting typing-extensions>=4.5.0 (from llama-cpp-python==0.1.78)\r\n",
      "  Obtaining dependency information for typing-extensions>=4.5.0 from https://files.pythonhosted.org/packages/b7/f4/6a90020cd2d93349b442bfcb657d0dc91eee65491600b2cb1d388bc98e6b/typing_extensions-4.9.0-py3-none-any.whl.metadata\r\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Collecting numpy>=1.20.0 (from llama-cpp-python==0.1.78)\r\n",
      "  Obtaining dependency information for numpy>=1.20.0 from https://files.pythonhosted.org/packages/7d/24/ce71dc08f06534269f66e73c04f5709ee024a1afe92a7b6e1d73f158e1f8/numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata\r\n",
      "  Downloading numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (61 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.1/61.1 kB\u001B[0m \u001B[31m176.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python==0.1.78)\r\n",
      "  Obtaining dependency information for diskcache>=5.6.1 from https://files.pythonhosted.org/packages/3f/27/4570e78fc0bf5ea0ca45eb1de3818a23787af9b390c0b0a0033a1b8236f9/diskcache-5.6.3-py3-none-any.whl.metadata\r\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\r\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m45.5/45.5 kB\u001B[0m \u001B[31m118.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading numpy-1.26.4-cp39-cp39-macosx_10_9_x86_64.whl (20.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m20.6/20.6 MB\u001B[0m \u001B[31m114.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\r\n",
      "Building wheels for collected packages: llama-cpp-python\r\n",
      "  Running command Building wheel for llama-cpp-python (pyproject.toml)\r\n",
      "\r\n",
      "\r\n",
      "  --------------------------------------------------------------------------------\r\n",
      "  -- Trying 'Ninja' generator\r\n",
      "  --------------------------------\r\n",
      "  ---------------------------\r\n",
      "  ----------------------\r\n",
      "  -----------------\r\n",
      "  ------------\r\n",
      "  -------\r\n",
      "  --\r\n",
      "  \u001B[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\r\n",
      "    Compatibility with CMake < 3.5 will be removed from a future version of\r\n",
      "    CMake.\r\n",
      "\r\n",
      "    Update the VERSION argument <min> value or use a ...<max> suffix to tell\r\n",
      "    CMake that the project does not need compatibility with older versions.\r\n",
      "\r\n",
      "  \u001B[0mNot searching for unused variables given on the command line.\r\n",
      "\r\n",
      "  -- The C compiler identification is AppleClang 15.0.0.15000040\r\n",
      "  -- Detecting C compiler ABI info\r\n",
      "  -- Detecting C compiler ABI info - done\r\n",
      "  -- Check for working C compiler: /Library/Developer/CommandLineTools/usr/bin/cc - skipped\r\n",
      "  -- Detecting C compile features\r\n",
      "  -- Detecting C compile features - done\r\n",
      "  -- The CXX compiler identification is AppleClang 15.0.0.15000040\r\n",
      "  -- Detecting CXX compiler ABI info\r\n",
      "  -- Detecting CXX compiler ABI info - done\r\n",
      "  -- Check for working CXX compiler: /Library/Developer/CommandLineTools/usr/bin/c++ - skipped\r\n",
      "  -- Detecting CXX compile features\r\n",
      "  -- Detecting CXX compile features - done\r\n",
      "  -- Configuring done (17.4s)\r\n",
      "  -- Generating done (0.0s)\r\n",
      "  -- Build files have been written to: /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/_cmake_test_compile/build\r\n",
      "  --\r\n",
      "  -------\r\n",
      "  ------------\r\n",
      "  -----------------\r\n",
      "  ----------------------\r\n",
      "  ---------------------------\r\n",
      "  --------------------------------\r\n",
      "  -- Trying 'Ninja' generator - success\r\n",
      "  --------------------------------------------------------------------------------\r\n",
      "\r\n",
      "  Configuring Project\r\n",
      "    Working directory:\r\n",
      "      /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/_skbuild/macosx-14.0-x86_64-3.9/cmake-build\r\n",
      "    Command:\r\n",
      "      /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-build-env-rbj67rzw/overlay/lib/python3.9/site-packages/cmake/data/bin/cmake /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e -G Ninja -DCMAKE_MAKE_PROGRAM:FILEPATH=/private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-build-env-rbj67rzw/overlay/lib/python3.9/site-packages/ninja/data/bin/ninja --no-warn-unused-cli -DCMAKE_INSTALL_PREFIX:PATH=/private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/_skbuild/macosx-14.0-x86_64-3.9/cmake-install -DPYTHON_VERSION_STRING:STRING=3.9.18 -DSKBUILD:INTERNAL=TRUE -DCMAKE_MODULE_PATH:PATH=/private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-build-env-rbj67rzw/overlay/lib/python3.9/site-packages/skbuild/resources/cmake -DPYTHON_EXECUTABLE:PATH=/Users/Siar/Desktop/AWT-repos/generative-agents/venv/bin/python -DPYTHON_INCLUDE_DIR:PATH=/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/include/python3.9 -DPYTHON_LIBRARY:PATH=/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/lib/libpython3.9.dylib -DPython_EXECUTABLE:PATH=/Users/Siar/Desktop/AWT-repos/generative-agents/venv/bin/python -DPython_ROOT_DIR:PATH=/Users/Siar/Desktop/AWT-repos/generative-agents/venv -DPython_FIND_REGISTRY:STRING=NEVER -DPython_INCLUDE_DIR:PATH=/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/include/python3.9 -DPython3_EXECUTABLE:PATH=/Users/Siar/Desktop/AWT-repos/generative-agents/venv/bin/python -DPython3_ROOT_DIR:PATH=/Users/Siar/Desktop/AWT-repos/generative-agents/venv -DPython3_FIND_REGISTRY:STRING=NEVER -DPython3_INCLUDE_DIR:PATH=/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/include/python3.9 -DCMAKE_MAKE_PROGRAM:FILEPATH=/private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-build-env-rbj67rzw/overlay/lib/python3.9/site-packages/ninja/data/bin/ninja -DLLAMA_CUBLAS=on -DCMAKE_OSX_DEPLOYMENT_TARGET:STRING=14.0 -DCMAKE_OSX_ARCHITECTURES:STRING=x86_64 -DCMAKE_BUILD_TYPE:STRING=Release -DLLAMA_CUBLAS=on\r\n",
      "\r\n",
      "  Not searching for unused variables given on the command line.\r\n",
      "  -- The C compiler identification is AppleClang 15.0.0.15000040\r\n",
      "  -- The CXX compiler identification is AppleClang 15.0.0.15000040\r\n",
      "  -- Detecting C compiler ABI info\r\n",
      "  -- Detecting C compiler ABI info - done\r\n",
      "  -- Check for working C compiler: /Library/Developer/CommandLineTools/usr/bin/cc - skipped\r\n",
      "  -- Detecting C compile features\r\n",
      "  -- Detecting C compile features - done\r\n",
      "  -- Detecting CXX compiler ABI info\r\n",
      "  -- Detecting CXX compiler ABI info - done\r\n",
      "  -- Check for working CXX compiler: /Library/Developer/CommandLineTools/usr/bin/c++ - skipped\r\n",
      "  -- Detecting CXX compile features\r\n",
      "  -- Detecting CXX compile features - done\r\n",
      "  -- Found Git: /usr/bin/git (found version \"2.39.3 (Apple Git-145)\")\r\n",
      "  fatal: not a git repository (or any of the parent directories): .git\r\n",
      "  fatal: not a git repository (or any of the parent directories): .git\r\n",
      "  \u001B[33mCMake Warning at vendor/llama.cpp/CMakeLists.txt:117 (message):\r\n",
      "    Git repository not found; to enable automatic generation of build info,\r\n",
      "    make sure Git is installed and the project is a Git repository.\r\n",
      "\r\n",
      "  \u001B[0m\r\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\r\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\r\n",
      "  -- Found Threads: TRUE\r\n",
      "  -- Accelerate framework found\r\n",
      "  -- Could not find nvcc, please set CUDAToolkit_ROOT.\r\n",
      "  \u001B[33mCMake Warning at vendor/llama.cpp/CMakeLists.txt:291 (message):\r\n",
      "    cuBLAS not found\r\n",
      "\r\n",
      "  \u001B[0m\r\n",
      "  -- CMAKE_SYSTEM_PROCESSOR: x86_64\r\n",
      "  -- x86 detected\r\n",
      "  -- Configuring done (2.2s)\r\n",
      "  -- Generating done (0.0s)\r\n",
      "  -- Build files have been written to: /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/_skbuild/macosx-14.0-x86_64-3.9/cmake-build\r\n",
      "  [1/8] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o\r\n",
      "  [2/8] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/k_quants.c.o\r\n",
      "  [3/8] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o\r\n",
      "  /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/vendor/llama.cpp/ggml.c:2346:5: warning: implicit conversion increases floating-point precision: 'float' to 'ggml_float' (aka 'double') [-Wdouble-promotion]\r\n",
      "      GGML_F16_VEC_REDUCE(sumf, sum);\r\n",
      "      ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/vendor/llama.cpp/ggml.c:1978:37: note: expanded from macro 'GGML_F16_VEC_REDUCE'\r\n",
      "  #define GGML_F16_VEC_REDUCE         GGML_F32Cx8_REDUCE\r\n",
      "                                      ^\r\n",
      "  /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/vendor/llama.cpp/ggml.c:1968:33: note: expanded from macro 'GGML_F32Cx8_REDUCE'\r\n",
      "  #define GGML_F32Cx8_REDUCE      GGML_F32x8_REDUCE\r\n",
      "                                  ^\r\n",
      "  /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/vendor/llama.cpp/ggml.c:1914:11: note: expanded from macro 'GGML_F32x8_REDUCE'\r\n",
      "      res = _mm_cvtss_f32(_mm_hadd_ps(t1, t1));                     \\\r\n",
      "          ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/vendor/llama.cpp/ggml.c:3388:9: warning: implicit conversion increases floating-point precision: 'float' to 'ggml_float' (aka 'double') [-Wdouble-promotion]\r\n",
      "          GGML_F16_VEC_REDUCE(sumf[k], sum[k]);\r\n",
      "          ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/vendor/llama.cpp/ggml.c:1978:37: note: expanded from macro 'GGML_F16_VEC_REDUCE'\r\n",
      "  #define GGML_F16_VEC_REDUCE         GGML_F32Cx8_REDUCE\r\n",
      "                                      ^\r\n",
      "  /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/vendor/llama.cpp/ggml.c:1968:33: note: expanded from macro 'GGML_F32Cx8_REDUCE'\r\n",
      "  #define GGML_F32Cx8_REDUCE      GGML_F32x8_REDUCE\r\n",
      "                                  ^\r\n",
      "  /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/vendor/llama.cpp/ggml.c:1914:11: note: expanded from macro 'GGML_F32x8_REDUCE'\r\n",
      "      res = _mm_cvtss_f32(_mm_hadd_ps(t1, t1));                     \\\r\n",
      "          ~ ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n",
      "  /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/vendor/llama.cpp/ggml.c:10698:17: warning: 'cblas_sgemm' is deprecated: first deprecated in macOS 13.3 - An updated CBLAS interface supporting ILP64 is available.  Please compile with -DACCELERATE_NEW_LAPACK to access the new headers and -DACCELERATE_LAPACK_ILP64 for ILP64 support. [-Wdeprecated-declarations]\r\n",
      "                  cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasTrans,\r\n",
      "                  ^\r\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX14.0.sdk/System/Library/Frameworks/vecLib.framework/Headers/cblas.h:610:6: note: 'cblas_sgemm' has been explicitly marked deprecated here\r\n",
      "  void cblas_sgemm(const enum CBLAS_ORDER __Order,\r\n",
      "       ^\r\n",
      "  /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/vendor/llama.cpp/ggml.c:603:23: warning: unused function 'mul_sum_i8_pairs' [-Wunused-function]\r\n",
      "  static inline __m128i mul_sum_i8_pairs(const __m128i x, const __m128i y) {\r\n",
      "                        ^\r\n",
      "  /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/vendor/llama.cpp/ggml.c:634:19: warning: unused function 'hsum_i32_4' [-Wunused-function]\r\n",
      "  static inline int hsum_i32_4(const __m128i a) {\r\n",
      "                    ^\r\n",
      "  /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/vendor/llama.cpp/ggml.c:699:23: warning: unused function 'packNibbles' [-Wunused-function]\r\n",
      "  static inline __m128i packNibbles( __m256i bytes )\r\n",
      "                        ^\r\n",
      "  6 warnings generated.\r\n",
      "  [4/8] Linking C shared library vendor/llama.cpp/libggml_shared.dylib\r\n",
      "  [5/8] Linking C static library vendor/llama.cpp/libggml_static.a\r\n",
      "  [6/8] Building CXX object vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o\r\n",
      "  [7/8] Linking CXX shared library vendor/llama.cpp/libllama.dylib\r\n",
      "  [7/8] Install the project...\r\n",
      "  -- Install configuration: \"Release\"\r\n",
      "  -- Installing: /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/_skbuild/macosx-14.0-x86_64-3.9/cmake-install/lib/libggml_shared.dylib\r\n",
      "  -- Installing: /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/_skbuild/macosx-14.0-x86_64-3.9/cmake-install/lib/libllama.dylib\r\n",
      "  -- Installing: /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/_skbuild/macosx-14.0-x86_64-3.9/cmake-install/bin/convert.py\r\n",
      "  -- Installing: /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/_skbuild/macosx-14.0-x86_64-3.9/cmake-install/bin/convert-lora-to-ggml.py\r\n",
      "  -- Installing: /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/_skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/libllama.dylib\r\n",
      "\r\n",
      "  copying llama_cpp/llama_types.py -> _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/llama_types.py\r\n",
      "  copying llama_cpp/__init__.py -> _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/__init__.py\r\n",
      "  copying llama_cpp/llama_cpp.py -> _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/llama_cpp.py\r\n",
      "  copying llama_cpp/llama.py -> _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/llama.py\r\n",
      "  copying llama_cpp/utils.py -> _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/utils.py\r\n",
      "  copying llama_cpp/llama_grammar.py -> _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/llama_grammar.py\r\n",
      "  creating directory _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/server\r\n",
      "  copying llama_cpp/server/__init__.py -> _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/server/__init__.py\r\n",
      "  copying llama_cpp/server/app.py -> _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/server/app.py\r\n",
      "  copying llama_cpp/server/__main__.py -> _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/server/__main__.py\r\n",
      "  copying /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-install-z0h0q623/llama-cpp-python_daf2a43005204cf8967d96c318040c6e/llama_cpp/py.typed -> _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/py.typed\r\n",
      "\r\n",
      "  running bdist_wheel\r\n",
      "  running build\r\n",
      "  running build_py\r\n",
      "  creating _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39\r\n",
      "  creating _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/llama_types.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/__init__.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/llama_cpp.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/llama.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/utils.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/llama_grammar.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp\r\n",
      "  creating _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/server\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/server/__init__.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/server\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/server/app.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/server\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/server/__main__.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/server\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/py.typed -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/libllama.dylib -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/llama_types.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/__init__.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/llama_cpp.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/llama.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/utils.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/llama_grammar.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/server/__init__.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/server\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/server/app.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/server\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/llama_cpp/server/__main__.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/server\r\n",
      "  copied 9 files\r\n",
      "  running build_ext\r\n",
      "  installing to _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel\r\n",
      "  running install\r\n",
      "  running install_lib\r\n",
      "  creating _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64\r\n",
      "  creating _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel\r\n",
      "  creating _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/llama_types.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/__init__.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/llama_cpp.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp\r\n",
      "  creating _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp/server\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/server/__init__.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp/server\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/server/app.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp/server\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/server/__main__.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp/server\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/libllama.dylib -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/llama.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/utils.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/llama_grammar.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/setuptools/lib.macosx-14.0-x86_64-cpython-39/llama_cpp/py.typed -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp\r\n",
      "  copied 11 files\r\n",
      "  running install_data\r\n",
      "  creating _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp_python-0.1.78.data\r\n",
      "  creating _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp_python-0.1.78.data/data\r\n",
      "  creating _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp_python-0.1.78.data/data/lib\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/lib/libggml_shared.dylib -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp_python-0.1.78.data/data/lib\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/lib/libllama.dylib -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp_python-0.1.78.data/data/lib\r\n",
      "  creating _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp_python-0.1.78.data/data/bin\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/bin/convert-lora-to-ggml.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp_python-0.1.78.data/data/bin\r\n",
      "  copying _skbuild/macosx-14.0-x86_64-3.9/cmake-install/bin/convert.py -> _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp_python-0.1.78.data/data/bin\r\n",
      "  running install_egg_info\r\n",
      "  running egg_info\r\n",
      "  writing llama_cpp_python.egg-info/PKG-INFO\r\n",
      "  writing dependency_links to llama_cpp_python.egg-info/dependency_links.txt\r\n",
      "  writing requirements to llama_cpp_python.egg-info/requires.txt\r\n",
      "  writing top-level names to llama_cpp_python.egg-info/top_level.txt\r\n",
      "  reading manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\r\n",
      "  adding license file 'LICENSE.md'\r\n",
      "  writing manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\r\n",
      "  Copying llama_cpp_python.egg-info to _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp_python-0.1.78-py3.9.egg-info\r\n",
      "  running install_scripts\r\n",
      "  copied 0 files\r\n",
      "  creating _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel/llama_cpp_python-0.1.78.dist-info/WHEEL\r\n",
      "  creating '/private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-wheel-hlemkx03/.tmp-t5wbcv34/llama_cpp_python-0.1.78-cp39-cp39-macosx_14_0_x86_64.whl' and adding '_skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel' to it\r\n",
      "  adding 'llama_cpp/__init__.py'\r\n",
      "  adding 'llama_cpp/libllama.dylib'\r\n",
      "  adding 'llama_cpp/llama.py'\r\n",
      "  adding 'llama_cpp/llama_cpp.py'\r\n",
      "  adding 'llama_cpp/llama_grammar.py'\r\n",
      "  adding 'llama_cpp/llama_types.py'\r\n",
      "  adding 'llama_cpp/py.typed'\r\n",
      "  adding 'llama_cpp/utils.py'\r\n",
      "  adding 'llama_cpp/server/__init__.py'\r\n",
      "  adding 'llama_cpp/server/__main__.py'\r\n",
      "  adding 'llama_cpp/server/app.py'\r\n",
      "  adding 'llama_cpp_python-0.1.78.data/data/bin/convert-lora-to-ggml.py'\r\n",
      "  adding 'llama_cpp_python-0.1.78.data/data/bin/convert.py'\r\n",
      "  adding 'llama_cpp_python-0.1.78.data/data/lib/libggml_shared.dylib'\r\n",
      "  adding 'llama_cpp_python-0.1.78.data/data/lib/libllama.dylib'\r\n",
      "  adding 'llama_cpp_python-0.1.78.dist-info/LICENSE.md'\r\n",
      "  adding 'llama_cpp_python-0.1.78.dist-info/METADATA'\r\n",
      "  adding 'llama_cpp_python-0.1.78.dist-info/WHEEL'\r\n",
      "  adding 'llama_cpp_python-0.1.78.dist-info/top_level.txt'\r\n",
      "  adding 'llama_cpp_python-0.1.78.dist-info/RECORD'\r\n",
      "  removing _skbuild/macosx-14.0-x86_64-3.9/setuptools/bdist.macosx-14.0-x86_64/wheel\r\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\r\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.78-cp39-cp39-macosx_14_0_x86_64.whl size=716891 sha256=3b9975b4574741e7581674dd6302f107cf74208bb159616ebfb6b0052dc05cca\r\n",
      "  Stored in directory: /private/var/folders/2s/pm32d3n97zq66c41rxds6fch0000gp/T/pip-ephem-wheel-cache-5ef9a3o2/wheels/0c/b7/c5/44bc04b1032871ad214d9e23594bbffeccff9278f98691d8b3\r\n",
      "Successfully built llama-cpp-python\r\n",
      "Installing collected packages: typing-extensions, numpy, diskcache, llama-cpp-python\r\n",
      "  Attempting uninstall: typing-extensions\r\n",
      "    Found existing installation: typing_extensions 4.9.0\r\n",
      "    Uninstalling typing_extensions-4.9.0:\r\n",
      "      Removing file or directory /Users/Siar/Desktop/AWT-repos/generative-agents/venv/lib/python3.9/site-packages/__pycache__/typing_extensions.cpython-39.pyc\r\n",
      "      Removing file or directory /Users/Siar/Desktop/AWT-repos/generative-agents/venv/lib/python3.9/site-packages/typing_extensions-4.9.0.dist-info/\r\n",
      "      Removing file or directory /Users/Siar/Desktop/AWT-repos/generative-agents/venv/lib/python3.9/site-packages/typing_extensions.py\r\n",
      "      Successfully uninstalled typing_extensions-4.9.0\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.26.3\r\n",
      "    Uninstalling numpy-1.26.3:\r\n",
      "      Removing file or directory /Users/Siar/Desktop/AWT-repos/generative-agents/venv/bin/f2py\r\n",
      "      Removing file or directory /Users/Siar/Desktop/AWT-repos/generative-agents/venv/lib/python3.9/site-packages/numpy-1.26.3.dist-info/\r\n",
      "      Removing file or directory /Users/Siar/Desktop/AWT-repos/generative-agents/venv/lib/python3.9/site-packages/numpy/\r\n",
      "      Successfully uninstalled numpy-1.26.3\r\n",
      "  changing mode of /Users/Siar/Desktop/AWT-repos/generative-agents/venv/bin/f2py to 755\r\n",
      "  Attempting uninstall: diskcache\r\n",
      "    Found existing installation: diskcache 5.6.3\r\n",
      "    Uninstalling diskcache-5.6.3:\r\n",
      "      Removing file or directory /Users/Siar/Desktop/AWT-repos/generative-agents/venv/lib/python3.9/site-packages/diskcache-5.6.3.dist-info/\r\n",
      "      Removing file or directory /Users/Siar/Desktop/AWT-repos/generative-agents/venv/lib/python3.9/site-packages/diskcache/\r\n",
      "      Successfully uninstalled diskcache-5.6.3\r\n",
      "  Attempting uninstall: llama-cpp-python\r\n",
      "    Found existing installation: llama_cpp_python 0.1.78\r\n",
      "    Uninstalling llama_cpp_python-0.1.78:\r\n",
      "      Removing file or directory /Users/Siar/Desktop/AWT-repos/generative-agents/venv/bin/__pycache__/\r\n",
      "      Removing file or directory /Users/Siar/Desktop/AWT-repos/generative-agents/venv/bin/convert-lora-to-ggml.py\r\n",
      "      Removing file or directory /Users/Siar/Desktop/AWT-repos/generative-agents/venv/bin/convert.py\r\n",
      "      Removing file or directory /Users/Siar/Desktop/AWT-repos/generative-agents/venv/lib/libggml_shared.dylib\r\n",
      "      Removing file or directory /Users/Siar/Desktop/AWT-repos/generative-agents/venv/lib/libllama.dylib\r\n",
      "      Removing file or directory /Users/Siar/Desktop/AWT-repos/generative-agents/venv/lib/python3.9/site-packages/llama_cpp/\r\n",
      "      Removing file or directory /Users/Siar/Desktop/AWT-repos/generative-agents/venv/lib/python3.9/site-packages/llama_cpp_python-0.1.78.dist-info/\r\n",
      "      Successfully uninstalled llama_cpp_python-0.1.78\r\n",
      "Successfully installed diskcache-5.6.3 llama-cpp-python-0.1.78 numpy-1.26.4 typing-extensions-4.9.0\r\n"
     ]
    }
   ],
   "source": [
    "# GPU llama-cpp-python\n",
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.78 --force-reinstall --upgrade --no-cache-dir --verbose"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-11T13:46:10.662565Z",
     "start_time": "2024-02-11T13:45:25.484101Z"
    }
   },
   "id": "7fa8f447661aebc7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from huggingface_hub import hf_hub_download\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.llms import LlamaCpp\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import faiss\n",
    "import requests\n",
    "import random\n",
    "from llama_cpp import Llama"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-11T13:46:59.051783Z"
    }
   },
   "id": "7c9cbdbe75cf6475"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/paraphrase-xlm-r-multilingual-v1')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b387769798011af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Change the model name and store it in a variable\n",
    "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGUF\"\n",
    "model_basename = \"llama-2-13b-chat.Q5_K_S.gguf\" # the model is in bin format\n",
    "\n",
    "# Change the FAISS index path to use the local file\n",
    "DB_FAISS_PATH = \"/vectorstore/db_faiss/faiss.index\"\n",
    "\n",
    "# Download the model using HF-Hub\n",
    "model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)\n",
    "\n",
    "lcpp_llm = None\n",
    "lcpp_llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_threads=2, # CPU cores\n",
    "    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "    n_gpu_layers=43, # Change this value based on your model and your GPU VRAM pool.\n",
    "    n_ctx=4096, # Context window\n",
    ")\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "loader = CSVLoader(file_path=\"/data/mc-dataset.csv\", encoding=\"utf-8\", csv_args={'delimiter': ','})\n",
    "data = loader.load()\n",
    "\n",
    "# Change the text splitter import to use the langchain version\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512, chunk_overlap=20\n",
    ")\n",
    "\n",
    "# Split the dataset into text chunks\n",
    "text_chunks = text_splitter.split_documents(data)\n",
    "\n",
    "text_strings = [doc.page_content for doc in text_chunks]\n",
    "\n",
    "# Initialize the model from the sentence-transformers library\n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-xlm-r-multilingual-v1')\n",
    "\n",
    "def get_embeddings(texts):\n",
    "    # texts should be a list of strings\n",
    "    embeddings = model.encode(texts, show_progress_bar=True)\n",
    "    return embeddings\n",
    "\n",
    "# Change the embedding import to use the langchain version\n",
    "embeddings = get_embeddings(text_strings)\n",
    "\n",
    "# Extract the embeddings from the FAISS index\n",
    "#docsearch = FAISS.from_documents(text_chunks, embeddings)\n",
    "\n",
    "#docsearch.save_local(DB_FAISS_PATH)\n",
    "dimension = embeddings.shape[1]  # Get the dimensionality of your embeddings\n",
    "index = faiss.IndexFlatL2(dimension)  # Create a flat (brute-force) search index\n",
    "\n",
    "# FAISS requires the data type to be float32\n",
    "if embeddings.dtype != np.float32:\n",
    "    embeddings = embeddings.astype(np.float32)\n",
    "\n",
    "index.add(embeddings)  # Add your embeddings to the index\n",
    "\n",
    "# To save the index to disk\n",
    "faiss.write_index(index, DB_FAISS_PATH)\n",
    "\n",
    "#NEUNEUNEU\n",
    "def fetch_question_from_api(question_id):\n",
    "    \"\"\"Fetch a question from the API.\"\"\"\n",
    "    api_url = f'http://3.139.84.244:8000/questions/{question_id}'\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Error fetching question: HTTP {response.status_code}\")\n",
    "            return None\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Exception when fetching question: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_exam(num_questions=50):\n",
    "    \"\"\"Generate an exam with a specified number of questions.\"\"\"\n",
    "    exam = []\n",
    "    question_ids = random.sample(range(1, 490), num_questions)  # Randomly select question IDs\n",
    "\n",
    "    for q_id in question_ids:\n",
    "        question = fetch_question_from_api(q_id)\n",
    "        if question:\n",
    "            exam.append(question)\n",
    "        else:\n",
    "            print(f\"Failed to fetch question with ID: {q_id}\")\n",
    "\n",
    "    return exam\n",
    "\n",
    "def generate_response(agent, prompt):\n",
    "    \"\"\"Generate a response using the specified agent.\"\"\"\n",
    "    response = agent(\n",
    "        prompt=prompt,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.5,\n",
    "        top_p=0.95,\n",
    "        repeat_penalty=1.2,\n",
    "        top_k=50,\n",
    "        stop=['USER:', 'ASSISTANT:'],\n",
    "        echo=True\n",
    "    )\n",
    "    return response[\"choices\"][0][\"text\"]\n",
    "\n",
    "\n",
    "def agent_interaction(agent_1, agent_2, question_id):\n",
    "    \"\"\"Simulate the interaction between two agents.\"\"\"\n",
    "    question_data = fetch_question_from_api(question_id)\n",
    "    if not question_data:\n",
    "        print(\"Question not found.\")\n",
    "        return\n",
    "\n",
    "    question = question_data['Question']\n",
    "    choices = f\"{question_data['Choice_A']} {question_data['Choice_B']} {question_data['Choice_C']} {question_data['Choice_D']} {question_data['Choice_E']}\"\n",
    "    correct_answer = question_data['Correct_Answer']\n",
    "\n",
    "    # Agent 1 asks the question\n",
    "    prompt_for_agent_2 = f\"Question: {question} {choices}\\nAnswer:\"\n",
    "    response_from_agent_2 = generate_response(agent_2, prompt_for_agent_2)\n",
    "\n",
    "    # Print the agent's response (only the letter)\n",
    "    print(f\"Agent 2's Response: {response_from_agent_2}\")\n",
    "\n",
    "    # Agent 1 provides the full correct answer from the API\n",
    "    full_correct_answer = f\"The correct answer is: {correct_answer}, which is {question_data[f'Choice_{correct_answer}']}\"\n",
    "    print(full_correct_answer)\n",
    "\n",
    "\n",
    "def main():\n",
    "    for question_id in range(1, 11):  # Loop through questions 1 to 10\n",
    "        agent_interaction(lcpp_llm, lcpp_llm, question_id)\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f21c3f0cf8254dc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
